apiVersion: inference.networking.x-k8s.io/v1alpha2
kind: InferencePool
metadata:
  name: qwen2-0-5b
spec:
  extensionRef:
    name: qwen2-0-5b-epp
  selector:
    llm-d.ai/inferenceServing: "true"
    llm-d.ai/model: qwen2-0-5b
  targetPortNumber: 8000
